{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Citation for the below code\n",
    "'''\n",
    "Title: CCMEO Microplot Clipper Script\n",
    "Authors: Galen Richardson, Julie Lovitt, Sylvain Leblanc\n",
    "Date: 02-25-2021\n",
    "Version: 1.8\n",
    "https://www.nrcan.gc.ca/science-and-data/research-centres-and-labs/canada-centre-remote-sensing/21749\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image, ImageFilter\n",
    "import os,cv2,time,shutil,csv\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.dpi'] = 150 \n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.linear_model import TheilSenRegressor,RANSACRegressor\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Directory where the photos ready to be clipped are located\n",
    "photo_dir=r'C:\\Users\\gamr0\\Desktop\\clip'\n",
    "\n",
    "#Directory where the clipped photos and b/w photos(from stage 1) are output\n",
    "clip_dir = r'C:\\Users\\gamr0\\Desktop\\m'\n",
    "\n",
    "#Variable which defines what kind of box (red/orange, or blue). valid enteries are \"red\" or \"blue\"\n",
    "red_blue = \"red\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 1: Defining the Box"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Directory Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def Testing_dir_setup(photo_dir, clip_dir):\n",
    "    global in_list\n",
    "    global bw_list\n",
    "    global clip_list\n",
    "    #if bw/clip folders exist delete the contents, if not create new folders\n",
    "    if os.path.exists(clip_dir):\n",
    "        shutil.rmtree(clip_dir)\n",
    "        os.makedirs(clip_dir)\n",
    "    else:\n",
    "        os.makedirs(clip_dir)\n",
    "    in_list=[]\n",
    "    bw_list=[]\n",
    "    clip_list=[]\n",
    "    for path,subdir,files in os.walk(photo_dir):\n",
    "        for file in files:\n",
    "            in_list.append(photo_dir+'\\\\'+file)\n",
    "            bw_list.append(clip_dir+'\\\\'+file)\n",
    "            clip_list.append(clip_dir+'\\\\'+file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resizing and bluring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def open_resize(input):\n",
    "    img=Image.open(input)\n",
    "    IMG_W,IMG_H = 3000,3000\n",
    "    #resizing to known aspect ratios and approx image sizes\n",
    "    if (img.size[0]/ img.size[1]) >1.19:\n",
    "        IMG_W,IMG_H= 3600,3000\n",
    "    if (img.size[0]/ img.size[1]) >1.29:\n",
    "        IMG_W,IMG_H = 3840,3000\n",
    "    if (img.size[0]/ img.size[1]) >1.7:\n",
    "        IMG_W,IMG_H = 3840,2160\n",
    "    if (img.size[1]/ img.size[0]) >1.19:\n",
    "        IMG_W,IMG_H = 3000,3600\n",
    "    if (img.size[1]/ img.size[0]) >1.29:\n",
    "        IMG_W,IMG_H = 3000,3840\n",
    "    if (img.size[1]/ img.size[0]) >1.7:\n",
    "        IMG_W,IMG_H = 2160,3840\n",
    "    img=img.resize((IMG_W,IMG_H), Image.ANTIALIAS)\n",
    "    imgcv = np.array(img)\n",
    "    #adding blur\n",
    "    blur = cv2.GaussianBlur(imgcv,(5,5),0)\n",
    "    blur = cv2.GaussianBlur(blur,(11,11),0)#(old 10)\n",
    "    r, g, b = cv2.split(blur)\n",
    "    return r,g,b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moving window which looks for smoothness. Erosion, Dilation, mode filtering to remove outliers in smooth image. Smooth image is then thresholded compares to r,g,b targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def moving_window_range(input_bw,g,b):\n",
    "    #defining data and window size of\n",
    "    data,win_size,sub_win=input_bw,(12,12),9\n",
    "    rows = data.shape[0] - win_size[0] + 1\n",
    "    cols = data.shape[1] - win_size[1] + 1\n",
    "    slices = []\n",
    "    #creating slics (mini windows to work on)\n",
    "    for i in range(win_size[0]):\n",
    "        for j in range(win_size[1]):\n",
    "            slices.append(data[i:rows+i, j:cols+j])\n",
    "    #stacking the slices together, creating out image\n",
    "    stacked = np.dstack(slices)\n",
    "    outdata = np.zeros(((data.shape[0]-sub_win),(data.shape[1]-sub_win)), np.float32)\n",
    "    #np.ptp is finding the range of each slice, setting it to pix\n",
    "    outdata[1:-1, 1:-1] = np.ptp(stacked, 2)\n",
    "    out=outdata.astype(np.uint8)\n",
    "    outn= (255-out)\n",
    "    outn[outn <249]=0\n",
    "    outn[outn >=249]=255\n",
    "    #eroding, dilating, and moding to reduce noise\n",
    "    kernel = np.ones((3,3),np.uint8)\n",
    "    e1 = cv2.erode(outn,kernel,iterations = 2,borderType = 0)\n",
    "    d1 = cv2.dilate(e1,kernel,iterations = 2,borderType = 0)\n",
    "    pil=(Image.fromarray(d1)).filter(ImageFilter.ModeFilter(size=15))#old 15\n",
    "    cv=np.array(pil)\n",
    "    #finding coord of shrunken image from moving windo\n",
    "    x=input_bw.shape[0]-sub_win\n",
    "    y=input_bw.shape[1]-sub_win\n",
    "    #resizing r,g,b bands to smaller image\n",
    "    rnew=input_bw.copy()\n",
    "    b=cv2.resize(b,(y,x))\n",
    "    g=cv2.resize(g,(y,x))\n",
    "    rnew=cv2.resize(rnew,(y,x))\n",
    "    #thresholding bands, note that red threshold is inverted because we want red\n",
    "    rnew[rnew <210]=100 \n",
    "    rnew[rnew >=210]=0\n",
    "    rnew[rnew ==100]=255\n",
    "    b[b <230]=0 \n",
    "    b[b >=230]=255 \n",
    "    g[g <250]=0\n",
    "    g[g >=250]=255 \n",
    "    #subtracting thres bands from smoothed image to isolate smooth reddish pix\n",
    "    combo=cv-b-g-rnew\n",
    "\n",
    "    return combo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Script which is used to set up the process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def bw_processing():\n",
    "    start1 = time.time()\n",
    "    Testing_dir_setup(photo_dir,clip_dir)\n",
    "    for i in range (len(in_list)):\n",
    "        print('working on photo '+str(i+1))\n",
    "        r,g,b=open_resize(in_list[i])\n",
    "        if red_blue=='red':\n",
    "            out_bw = moving_window_range(r,g,b)\n",
    "        if red_blue=='blue':\n",
    "            out_bw = moving_window_range(b,g,r)\n",
    "        cv2.imwrite(bw_list[i],out_bw)\n",
    "    end1 = time.time()\n",
    "    print('Done in '+str(\"%.2f\"%(end1 - start1))+' sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on photo 1\n",
      "working on photo 2\n",
      "working on photo 3\n",
      "working on photo 4\n",
      "working on photo 5\n",
      "Done in 127.84 sec\n"
     ]
    }
   ],
   "source": [
    "bw_processing()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## Stage 2: Clip from Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the center, interior box size around center pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def crop_basics(bw_filepath,og_filepath):\n",
    "    #parameters for rest of script\n",
    "    global imgo\n",
    "    global imgbw\n",
    "    global centbw\n",
    "    global boxsize\n",
    "    #size of box around the center pixel,reduce if not getting good results\n",
    "    boxsize=500\n",
    "    imgbw=Image.open(bw_filepath)\n",
    "    imgo=Image.open(og_filepath)\n",
    "    imgo=imgo.resize((imgbw.size[0],imgbw.size[1]))\n",
    "    centbw=(int(imgbw.size[0]/2),int(imgbw.size[1]/2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creation of lists of coordinates from center box to outer box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def ret_lx_pos(start_posx, start_posy):\n",
    "    #returns leftx position\n",
    "    left_x=[]\n",
    "    for i in range(start_posx,5,-1):\n",
    "        px = imgbw.getpixel((i,start_posy))\n",
    "        left_x.append(px)\n",
    "    position=0\n",
    "    for i in left_x:\n",
    "        if i >200:\n",
    "            return (start_posx-position,start_posy)\n",
    "        position=position+1\n",
    "def L_cord_list():\n",
    "    #creates a list of all the leftx positions\n",
    "    L_cord=[]\n",
    "    for i in range(centbw[1]-boxsize,centbw[1]+boxsize,3):\n",
    "        x=ret_lx_pos(centbw[0], i)\n",
    "        if x != None:\n",
    "            L_cord.append(x)\n",
    "    return L_cord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def ret_rx_pos(start_posx, start_posy):\n",
    "    #returns rightx position\n",
    "    right_x=[]\n",
    "    for i in range (start_posx,(imgbw.size[0]-5),1):\n",
    "        px = imgbw.getpixel((i,start_posy))\n",
    "        right_x.append(px)\n",
    "    position=0\n",
    "    for i in right_x:\n",
    "        if i >200:\n",
    "            return (start_posx+position,start_posy)\n",
    "        position=position+1\n",
    "def R_cord_list():\n",
    "    #creates a list of all the rightx positions\n",
    "    R_cord=[]\n",
    "    for i in range(centbw[1]-boxsize,centbw[1]+boxsize,3):\n",
    "        x=ret_rx_pos(centbw[0], i)\n",
    "        if x != None:\n",
    "            R_cord.append(x)\n",
    "    return R_cord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def ret_dy_pos(start_posx, start_posy):\n",
    "    #returns down y position \n",
    "    down_y=[]\n",
    "    for i in range(start_posy,(imgbw.size[1]-5),1):\n",
    "        px = imgbw.getpixel((start_posx,i))\n",
    "        down_y.append(px)\n",
    "    position=0\n",
    "    for i in down_y:\n",
    "        if i >200:\n",
    "            return (start_posx,start_posy+position)\n",
    "        position=position+1\n",
    "def d_cord_list():\n",
    "    #creates a list of all down y position\n",
    "    d_cord=[]\n",
    "    for i in range(centbw[0]-boxsize,centbw[0]+boxsize,3):\n",
    "        x=ret_dy_pos(i, centbw[1])\n",
    "        if x != None:\n",
    "            d_cord.append(x)\n",
    "    return d_cord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def ret_uy_pos(start_posx, start_posy):\n",
    "    #returns up y postition\n",
    "    up_y=[]\n",
    "    for i in range(start_posy,5,-1):\n",
    "        px = imgbw.getpixel((start_posx,i))\n",
    "        up_y.append(px)\n",
    "    position=0\n",
    "    for i in up_y:\n",
    "        if i >200:\n",
    "            return (start_posx,start_posy-position)\n",
    "        position=position+1\n",
    "def u_cord_list():\n",
    "    #creates a list of all up y  positions\n",
    "    u_cord=[]\n",
    "    for i in range(centbw[0]-boxsize,centbw[0]+boxsize,3):\n",
    "        x=ret_uy_pos(i, centbw[1])\n",
    "        if x != None:\n",
    "            u_cord.append(x)\n",
    "    return u_cord"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the linear regressions used to define the box sides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def RL_theil(cord):\n",
    "    #regression function used for left and right sides\n",
    "    x,y = zip(*cord)\n",
    "    x=np.array((x)).reshape((-1, 1))\n",
    "    y=list(y)\n",
    "    modelT = TheilSenRegressor(max_iter=600).fit(x, y)\n",
    "    modelR= RANSACRegressor(max_trials=5000).fit(x,y)\n",
    "    modelL = linear_model.LinearRegression().fit(x, y)\n",
    "    tscore,rscore,lscore=abs(modelT.score(x, y)),abs(modelR.score(x, y)),abs(modelL.score(x, y))\n",
    "    #if the linear regression is good (over .95), it usually is the best score\n",
    "    if lscore > .95:\n",
    "        print('Linear init')\n",
    "        return modelL.coef_,modelL.intercept_\n",
    "    #if not linear, usually thiel over .9 is 2nd best\n",
    "    if tscore > .9:\n",
    "        print('Theil init')\n",
    "        return modelT.coef_,modelT.intercept_\n",
    "    #let the scores decide which one is best\n",
    "    if tscore > rscore and lscore:\n",
    "        print('Theil')\n",
    "        return modelT.coef_,modelT.intercept_\n",
    "    if rscore > tscore and lscore:\n",
    "        print('RANSAC')\n",
    "        return modelR.estimator_.coef_,modelR.estimator_.intercept_\n",
    "    if lscore > tscore and rscore:\n",
    "        print('Linear')\n",
    "        return modelL.coef_,modelL.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def UD_theil(cord):\n",
    "    #regression function used for up and down sides\n",
    "    #inverted y and x to avoid infinate slope\n",
    "    y,x = zip(*cord)\n",
    "    x=np.array((x)).reshape((-1, 1))\n",
    "    y=list(y)\n",
    "    modelT = TheilSenRegressor(max_iter=600).fit(x, y)\n",
    "    modelR= RANSACRegressor(max_trials=5000).fit(x,y)\n",
    "    modelL = linear_model.LinearRegression().fit(x, y)\n",
    "    tscore,rscore,lscore=abs(modelT.score(x, y)),abs(modelR.score(x, y)),abs(modelL.score(x, y))\n",
    "    #if the linear regression is good (over .95), it usually is the best score\n",
    "    if lscore > .95:\n",
    "        print('Linear init')\n",
    "        return modelL.coef_,modelL.intercept_\n",
    "    #if not linear, usually thiel over .9 is 2nd best\n",
    "    if tscore > .9:\n",
    "        print('Theil init')\n",
    "        return modelT.coef_,modelT.intercept_\n",
    "    #let the scores decide which one is best\n",
    "    if tscore > rscore and lscore:\n",
    "        print('Theil')\n",
    "        return modelT.coef_,modelT.intercept_\n",
    "    if rscore > tscore and lscore:\n",
    "        print('RANSAC')\n",
    "        return modelR.estimator_.coef_,modelR.estimator_.intercept_\n",
    "    if lscore > tscore and rscore:\n",
    "        print('Linear')\n",
    "        return modelL.coef_,modelL.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Equating and up/down regression to a left/right regression to find the corners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def Poly_corns(LR_slope, LR_int, UD_Slope, UD_int):\n",
    "    #using the slopes and intersepts, this functions finds polygon corners\n",
    "    #where an up/down reg meets a left/right\n",
    "    y=((LR_slope*UD_int)+LR_int)/(1-(LR_slope*UD_Slope))\n",
    "    x=UD_Slope*y+UD_int\n",
    "    return abs(int(x)),abs(int(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to get the 4 corners "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_corners():\n",
    "    #this function finds the coordinates of each side\n",
    "    L_cord=L_cord_list()\n",
    "    R_cord=R_cord_list()\n",
    "    D_cord=d_cord_list()\n",
    "    U_cord=u_cord_list()\n",
    "    #Contingency planning if there are no coordinates\n",
    "    if L_cord == []:\n",
    "        return 'no'\n",
    "    if R_cord == []:\n",
    "        return 'no'\n",
    "    if D_cord == []:\n",
    "        return 'no'\n",
    "    if U_cord == []:\n",
    "        return 'no'\n",
    "    #finds the regression for each side\n",
    "    slopeR,interceptR = RL_theil(R_cord)\n",
    "    slopeL,interceptL = RL_theil(L_cord)\n",
    "    slopeD,interceptD = UD_theil(D_cord)\n",
    "    slopeU,interceptU = UD_theil(U_cord)\n",
    "    #finds the corners where each regression meets\n",
    "    UL=list(Poly_corns(slopeL, interceptL, slopeU, interceptU))\n",
    "    UR=list(Poly_corns(slopeR, interceptR, slopeU, interceptU))\n",
    "    DL=list(Poly_corns(slopeL, interceptL, slopeD, interceptD))\n",
    "    DR=list(Poly_corns(slopeR, interceptR, slopeD, interceptD))\n",
    "    return UL,DL,DR,UR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the corners, this function creates a mask, clips to mask, then does a final bbox crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def process_clips(Corners):\n",
    "    global imgo\n",
    "    global imgbw\n",
    "    print (Corners)\n",
    "    image=imgo.resize((imgbw.size[0],imgbw.size[1]))\n",
    "    my_img = np.zeros((imgbw.size[1], imgbw.size[0], 3), dtype = \"uint8\")\n",
    "    pts = np.array(Corners, np.int32)\n",
    "    pts = pts.reshape((-1,1,2))\n",
    "    #creation of mask from corner points (white)\n",
    "    cv2.fillPoly(my_img, [pts], (255,255,255))\n",
    "    kernel = np.ones((10,10),np.uint8)\n",
    "    #shrinking the mask a bit so minimal box is in frma\n",
    "    e1 = cv2.erode(my_img,kernel,iterations = 16,borderType = 0)\n",
    "    #resizing and applying the mask\n",
    "    image=imgo.resize((imgbw.size[0],imgbw.size[1]))\n",
    "    result = cv2.bitwise_and(np.array(image), e1)\n",
    "    im = Image.fromarray(result)\n",
    "    y_nonzero, x_nonzero, _ = np.nonzero(im)\n",
    "    final = im.crop((np.min(x_nonzero), np.min(y_nonzero), np.max(x_nonzero), np.max(y_nonzero)))\n",
    "    return final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The standard deviation of the angles is how we can determine how skewed the angles of the box are. High angle sdv means that either the box in the image is skewed or there was a bad clip. This function determines sdev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def angle_sdv(output_corners):\n",
    "    ang_list=[]\n",
    "    i,j,k=0,0,0\n",
    "    for i in range (4):\n",
    "        #determining the angles of the corners\n",
    "        j,k=1,2\n",
    "        if i==2:\n",
    "            k= -2\n",
    "        if i==3:\n",
    "            j,k=-3,-2\n",
    "        a,b,c = np.array(output_corners[i]),np.array(output_corners[i+j]),np.array(output_corners[i+k])\n",
    "        ba = a - b\n",
    "        bc = c - b\n",
    "        cosine_angle = np.dot(ba, bc) / (np.linalg.norm(ba) * np.linalg.norm(bc))\n",
    "        angle = np.arccos(cosine_angle)\n",
    "        ang_list.append(np.degrees(angle))\n",
    "    #returning the standard deviation of the angle list\n",
    "    return np.std(ang_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "csv logging scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def cv_log(file, score):\n",
    "    with open(clip_dir+'\\potential_misclips.csv','a',newline='')as csvfile:\n",
    "        writer = csv.writer(csvfile, delimiter=',',\n",
    "            quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "        writer.writerow([file,score])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def Clipping_Workflow():\n",
    "    #the workflow of the clipping, uses in_list and BW_list as sources\n",
    "    global in_list\n",
    "    global bw_list\n",
    "    global clip_list\n",
    "    start2 = time.time()\n",
    "    scores=[]\n",
    "    with open(clip_dir+'\\potential_misclips.csv','w',newline='')as csvfile:\n",
    "        writer = csv.writer(csvfile, delimiter=',',\n",
    "            quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "        writer.writerow([\"Filename\",\"SDEV Angle Score\",\"Higher SDEV means greater variance in corner angles. This can because of bad clip or skewed image\"])\n",
    "    for i in range (len(in_list)):\n",
    "        print('working on photo '+str(i+1))\n",
    "        print(in_list[i])\n",
    "        crop_basics(bw_list[i],in_list[i])\n",
    "        output_corners=get_corners()\n",
    "        if output_corners == \"no\":\n",
    "            print('Skipping'+str(in_list[i]))\n",
    "            cv_log(in_list[i],'THIS IMAGE WAS NOT CROPPED DUE TO MISSING SIDE')\n",
    "            ogimg=Image.open(in_list[i])\n",
    "            ogimg.save(clip_list[i]) \n",
    "            continue\n",
    "        score=angle_sdv(output_corners)\n",
    "        if score >5:\n",
    "            print((str(int(score)))+' angle SDEV')\n",
    "        scores.append(score)\n",
    "        if score >5:\n",
    "            if score>15:\n",
    "                cv_log(clip_list[i],\"SKIPPED DUE TO HIGH SDEV\")\n",
    "                ogimg=Image.open(in_list[i])\n",
    "                ogimg.save(clip_list[i]) \n",
    "                continue\n",
    "            cv_log(clip_list[i],score)\n",
    "            final_img=process_clips(output_corners)\n",
    "            final_img.save(clip_list[i])\n",
    "        else:\n",
    "            final_img=process_clips(output_corners)\n",
    "            final_img.save(clip_list[i]) \n",
    "        #display\n",
    "        #plt.figure(figsize = (5,5))\n",
    "        #imgplot = plt.imshow(final_img)\n",
    "        #plt.show()\n",
    "    end2 = time.time()\n",
    "    print (\"Done in \"+str(\"%.2f\"%(end2 - start2))+' sec')\n",
    "    print(\"Average Angle Standard Deviation = \"+str(int((sum(scores) / len(scores)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on photo 1\n",
      "C:\\Users\\gamr0\\Desktop\\clip\\H1C.JPG\n",
      "RANSAC\n",
      "Linear init\n",
      "Linear init\n",
      "Linear init\n",
      "([430, 232], [534, 2940], [3111, 2780], [3018, 118])\n",
      "working on photo 2\n",
      "C:\\Users\\gamr0\\Desktop\\clip\\H1NW.JPG\n",
      "SkippingC:\\Users\\gamr0\\Desktop\\clip\\H1NW.JPG\n",
      "working on photo 3\n",
      "C:\\Users\\gamr0\\Desktop\\clip\\H1SE.JPG\n",
      "RANSAC\n",
      "Theil\n",
      "Linear init\n",
      "Linear init\n",
      "([482, 149], [575, 2738], [3083, 2689], [3044, 11])\n",
      "working on photo 4\n",
      "C:\\Users\\gamr0\\Desktop\\clip\\M4C.JPG\n",
      "RANSAC\n",
      "Linear init\n",
      "RANSAC\n",
      "Theil\n",
      "([232, 114], [450, 2808], [2901, 2741], [2938, 46])\n",
      "working on photo 5\n",
      "C:\\Users\\gamr0\\Desktop\\clip\\S9P2.JPG\n",
      "Theil init\n",
      "RANSAC\n",
      "Theil init\n",
      "Theil init\n",
      "16 angle SDEV\n",
      "Done in 20.00 sec\n",
      "Average Angle Standard Deviation = 5\n"
     ]
    }
   ],
   "source": [
    "Clipping_Workflow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
